![image](https://github.com/Rising-Stars-by-Sunshine/Yixin_Yue/assets/164857136/ae4f7b7e-c25b-48f2-9045-9ecb2e8e5dce)***Research Poster***

View-Only Canva poster: https://www.canva.com/design/DAGDhD16EJA/TarQnqZIsgok-ukf_uq2Xw/edit?utm_content=DAGDhD16EJA&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton

***Overleaf***

View-Only overleaf: https://www.overleaf.com/read/cdqcmzvrgphm#57d2fa

***Compiled PDF***

[CSECON206_Yixin_Yue.pdf](https://github.com/Rising-Stars-by-Sunshine/Yixin_Yue/files/15140567/CSECON206_Yixin_Yue.pdf)


**[Summarize the Background/Motivation]**
- What are the gaps between the existing literature and the pressing social and economic issues in the digital economy of complex system involving both human and AI agent that inspires your research?

The existing literature lacks systematic studies on how specific social roles and contextual factors influence AI decision-making in real-world game theory scenarios. This research aims to fill this gap by investigating how AI chatbots' behaviors differ when assigned roles such as economist and computer scientist in the Trust Game. By comparing the responses of different AI models, this study contributes to a deeper analysis of trust and trustworthiness among AI agents in economic contexts. Additionally, it offers valuable insights for the development of socially adaptive AI systems in diverse social realms.

**[Research Questions]**
- What are the questions that your research intends to answer?
- Why are the questions important?
- Why are the questions not answered by existing game theory literature?

How specific social roles and contextual factors influence AI decision-making in the context of Trust Game? How do distinct AI chatbots, such as ChatGPT and Copilot, differ in demonstrating social personalities when engaged in decision-making tasks?

These questions are crucial because they provide insights into developing effective and socially adaptive AI systems. This is also vital for risk mitigation when employing AI agents on automated decision-making in different social divisions.

While some research may touch upon AI behavior in game theory contexts, there is a gap in studies that delve into the nuanced effects of social roles and contexts that are not involved in the traditional game theory context concerning AI trust and decision-making.

**[Application Scenario]**
- In which real-world situation does your newly proposed game and/or solution concept or mechanism apply?
- What is the literature in other discipline such as psychology that could provide a behavioral foundation of your newly proposed game and/or solution concept, or mechanism?

The applies to real-world scenarios where AI-driven decision-making holds significance, especially within economic contexts emphasizing trust and cooperation. This includes domains such as online marketplaces, collaborative platforms, and automated decision-making systems in insurance and finance. In the realm of insurance and finance, AI is utilized for risk detection and financial prediction purposes. By leveraging machine learning algorithms, AI enhances fraud detection and improves forecasting accuracy by analyzing vast amounts of financial and policy data.  

Literature in psychology provides a rich foundation for understanding the behavioral aspects of the proposed game and solution concept. Concepts such as trust, reciprocity, and social roles have been extensively studied in psychology and can inform our understanding of how AI agents may behave in socio-economic contexts. Additionally, theories of decision-making, social cognition, and human-computer interaction can offer insights into the underlying mechanisms driving AI decision-making and interactions within the proposed game framework.

**[Methodology]**
- What is the key game theoretical or mechanism design framework that you build upon?
- What is the key computational or analytical tools that you apply to answer your requestion question?
- What is the advanced technology or interdisciplinary insights that you integrate into the existing methods that smartly solve your research question? 

My study builds upon the theoretical framework of the trust game proposed by Berg et al. (1995), which provides insights into trust and cooperation in economic interactions. I also incorporate the study by Ben-Ner and Halldorsson (2010), which offers a methodology for measuring trust and trustworthiness. By integrating these theoretical and methodological foundations, I aim to analyze trust and trustworthiness in the context of AI decision-making.
I will use python package QuantEcon to simulate the game environment and I will employ an extensive-form approach with the help of Game Theory Explorer.


**[Preliminary Results]**
- Can you provide a concrete illustration example of game theory or mechanism design that your approach significantly improves at least one objective of human welfare compared to existing research without your approach? 

Understanding our framework is vital for risk mitigation when employing AI agents on automated decision-making in different divisions, especially in the field where economists would interact with computer scientists, utilizing computational technologies to solve real-world economic problems. With the help and evaluation of our framewok, the interaction can be more reliable and trustworthy for human agents to understand.

**[Intellectual Merits and Practical impacts of your project]**
- Can you demonstrate the limitation of your current research that would inspire future research? For example, what are the other important objectives of human welfare that you approach does not consider yet? 
- Can you elaborate on how your research can be applied to improve individual, company, and government decisions in strategic scenarios or social choice issues? 
